---
title: "Deliverable 3"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA","MASS")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
#setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")

rm(list=ls())
load("data-INI2.RData")
```


# Y (Numeric Target). This variable will be the target for linear model building (connected to blocks Statistical Modeling I and II).

## Explicative Variables for modeling purposes are generally (not all in this dataset):

    * Socioeconomic variables: gender, age, education, type of work, etc
    * Activity in the current commercial campaign
    * Bank marketing history
    * Economic vars

## Multivariant Analysis conducted in previous deliverables has to be used to select the initial model. Students have some degrees in freedom in model building, but the following conditions are requested:

    * At least two numerical variables have to be considered as explicative variables for initial steps in model building, called covariates. Non-linear models have to be checked for consistency.
    * Select the most significant factors found in Multivariant Data Analysis as initial model factors.  Put some reasonable limits to initial model complexity.
    * You have to consider at least one interaction between a couple of factors and one interaction between factor and covariate.
    * Diagnostics of the final model have to be undertaken. Lack of fit observations and influence data have to be selected and discussed (connections to multidimensional outliers in Multivariant Data Analysis is highly valuable)
    
# Clasificación de las variables (modeling I y II).
    *   Variable Target "duration"
    *   Socio económicas: age, job, marital, education, default, housing, loan
    *   Activity in the current commercial campaign: Month, day of the week, duration, campaing, pdays(? preguntar), previous(? preguntar).  
    *   Bank marketing history: pdays, previous, poutcome.
    *   Economic vars: emp.var.rate, cons.price.index, cons.conf.index, euribor3m, number employed.

Si tuvieramos muchas variables explicativas podriamos utilizar el resultado del condes para saber cuáles de ellas utilizar, aunque también sería posible seleccionarlas a partir del análisis de componentes principales. Dado que tenemos poca cantidad de variables usamos todas. Empezamos utilizando lm para crear un modelo inicial del cual podemos ir descartando aquellas variables explicativas que nos parecen irrelevantes. Después contrastaremos nuestra selección usando el método Akaike o BIC, que en una sucesión de pasos va descartando variables.

```{r}
m1<-lm(duration~.,data=df[,c("duration",vars_num)])
summary(m1)
Anova(m1)
```

Viendo este volcado, vemos que todas las variables menos, campaign tienen un p-value superior al 0.05, sin embargo, pdays y previous estan por debajo de 0.1 lo que podriamos llegar a incorporarlas al modelo. El r-square es de 0.006393
# preguntar (que es r-square, que si es la suma de cuadrados de los residuos, esta debe ser cuanto menos mejor??) : multiple r-qsuare porque esta elevado al cuadrado, R:multiple R que quiere decir de la correlacon que tiene nuestro target con las predicciones de un modelo, eso seria el multple r. R^2=cor^2(y,y^y), Minetras el r-square es mayor quiere decir que nuestro modelo se ajusta bien por lo que es bueno, tiende a 1. No es importante si es negativo, lo que importa es la correlacion y ya esta. El ser negativo es irrelevante.  
#nos interesa que RSS sea lo mas pequeño posible y eso sera cuando la R2 sea lo mas grande posible. TSS(Total sum squares) este es con la mediana muestral del target, que se puede dividir por n si se quiere saber la variabilidad del target, da como resultado una estimacion de la varianza del target. Un estimador de una varianza de una variable sera esto.
# TSS = RSS(Nos interesa que sea muy prqueño para que nuestro modelo sea grande y quiere decir que el modelo es bueno) + ESS(Suma de cuadrados explicada. )-> esto es una suma de cuadrados que se tiene explicado en los slides de teoria.  El TSS esta relacionado con la variabilidad del target, el target debemos explicarlo con un modelo que nos..
# la formula y=Xb+E es importante para explicar el modelo. El epsilon es la parte residual que no esta en el modelo (es el residuo? si y no, tecnicamente no, pero conceptualmente si) esta formula se interpreta de forma conceptual0



Al ver el resultado de Anova, podemos ver resultados muy parecidos preguntar (diferencia de Anova y summary, ya que nos dan Pr prácticamente iguales)
# En estos casos no hay diferencia, pero en otros modelos como el de poly da diferentes de la clase del 3, el m20. En este caso es dif porque hay variables explicaticas que ponems en el modelo. Por ejemplo para ese estamos usando em.var.rate como pol. El metodo Anova si identifica que estas dos var estan relacionadas.(algo asi) el summary no lo podemos mirar si tenemos variables explicativas de factores.

# funcon predict para tener resultados dado un modelo.

Ahora probaremos selecionando las variables a partir de la criba anterior:
```{r}
m2<-lm(duration~campaign+pdays+previous,data=df)
summary(m2)
Anova(m2)

m3<-lm(duration~campaign+pdays,data=df)
summary(m3)
Anova(m3)

vif(m3)

par(mfrow=c(2,2))
plot(m3)
par(mfrow=c(1,1))

m=m3;
```

Viendo el resultado del lm con estas variables, podemos ver que previous da por encima de 0.2, por lo que también descartamos esta variable.

Al realizar nuevamente el lm con estas dos variables restantes, vemos que su p-value es inferior al 0.1, por lo que daríamos por concluida la criba.

Finalmente hacemos el análisis de residuos con vif, el cual nos dice que si nos da valores por debajo de 3 son buenos y por encima de 5 que las variables elegidas tienen redundancia y que inflará las varianzas. En nuestro caso, el resultado de las dos variables es inferior a 3.

Viendo el plot de la normal Q-Q, vemos que los valores distan mucho de la recta de referencia, con que podemos decir que su distribución no es para nada normal.

Ahora procederemos a comprobar el resultado usando la función step, conocida como Akaike o BIC.

```{r}
m4<-step(m1) # preguntar porque no quita mas? y porque da diferente al nuestro
vif(m4)
par(mfrow=c(2,2))
plot(m4)
par(mfrow=c(1,1))
```

En contraste a nuestra selección (pdays y campign), Akaike ha decidido conservar 5 variables. Aún así, podemos ver que el Akaike ha conservado las dos variables que nosotros hemos decidido dejar.

Hacemos el análisis de residuos con vif. En nuestro caso, el resultado de las 5 variables es inferior a 3. Al igual que en nuestro caso nos da una plot Q-Q totalmente desviada de las dist normal.

Si probamos con la versión bayesiana (del BIC):
```{r}
m5<-step(m1,k=log(nrow(df)))

par(mfrow=c(2,2))
plot(m5)
par(mfrow=c(1,1))
```

La versión bayesiana es conveniente usarla en casos de muestras grandes. En este caso vemos que se queda con una sola variable (campaign). preguntar ya que el enunciado dice que nos quedemos por lo menos con dos. (podemos usar Bic en vez del otro )

En este caso no podemos hacer el análisis de residuos con vif porque solo tenemos 1 variable.

Al igual que en nuestro caso nos da una plot Q-Q totalmente desviada de las dist normal.

Ahora procedemos a la transformación polinómica:
```{r}
boxcox(m,data=df)  #lambda 0 <- log(Y)

m6<-lm(log(duration)~.,data=df[,c("duration",vars_num)])
Anova(m6)

m7<-lm(log(duration)~campaign+pdays+nr.employed+euribor3m,data=df) # preguntar porque el vif da mas de 5, hay que quitar euribor o employed, si quitamos una la otra sube su pvalor. (si hay que sacar una porque si asi aunmente el pvalor)

summary(m7)
Anova(m7)

vif(m7)

par(mfrow=c(2,2))
plot(m7)
par(mfrow=c(1,1)) # problema de escala en standar resd pero como ya esta la vatiable transsformada no se pued hacer mas
```

Mediante la función boxcox descartamos la posibilidad de elevar el target al cuadrado, pero sí contemplamos aplicarle el logaritmo, pues el pico de la curva está entre 0 y 1 y bastante cerca del 0. No se obserban mejoras relevantes.

Ahora podemos probar con las versiones cuadráticas de las variables explicativas:
```{r}
m20<-lm(log(duration)~poly(campaign,2)+poly(pdays,2),data=df)
summary(m20)
Anova(m20)
vif(m20)
# la duration no teiene nada que ver ocn las numericas
```
%%%%%%% GUILLEM - Revisar ya que no aparece la variable emp.var.rate!!!!!!!!!!!!!
Vemos que para emp.var.rate, nos resulta útil usar su versión polinomica al cuadrado, ya que el p-value es significativamente menor. preguntar esta bien este analisis de polinomios? si los terminos cuadratircos son significativos
%%%%%%%
# practuca en  influent data, para estar seguros que el tema del diagnostico, hacer diagnotistico, residual plot, marginal plot, influence plot, porque en algun moemtno hay que hacerlo, se ha explicado esta semana.

# falta introducir todos los factores y repetir los procesos, falta mucho.
# podemos avanzar mas en sentirnos comodos en analisis de datos influentes.
# el analisis se hacee s al final cuando se tienen todas las caiables posibles unericas y factores.


# Outcome/Target : A binary response variable (Binary Target) will be the response variable for Binary Regression Models included in Statistical Modeling Part III.

Explicative Variables for modeling purposes are those available in dataset, exceptions will be indicated, if any.

Multivariant Analysis conducted in previous deliverables has to be used to select the initial model. Students have some degrees in freedom in model building, but the following conditions are requested:

    * Split the sample in work and test samples (consisting on a 80-20 split). Working data frame has to be used for model building purposes.

    *At least two numerical variables have to be considered as explicative variables for initial steps in model building.
    *Select the most significant factors according to feature selection as initial model factors.  Put some reasonable limits to initial model complexity.
    *You have to consider at least one interaction between a couple of factors and one interaction between factor and covariate.
    *Diagnostics of the final model have to be undertaken. Lack of fit observations and influence data have to be selected and discussed (connections to multidimensional outliers in Multivariant Data Analysis is highly valuable).
    *You have to predict Y (Binary Target)  in the Working Data Frame  vs the rest according to the best validated model that you can find and make a confusion matrix.
    *Make a confusion matrix in the Testing Data Frame for  Y  (Binary Target) according to the best validated model found.

```{r}

```



Confusion Matrix: When referring to the performance of a classification model, we are interested in the modelâs ability to correctly predict or separate the classes. When looking at the errors made by a classification model, the confusion matrix gives the full picture. Consider e.g. a three class problem with the classes A, and B. The confusion matrix shows how the predictions are made by the model. The rows correspond to the known class of the data, i.e. the labels in the data. The columns correspond to the predictions made by the model. The value of each of element in the matrix is the number of predictions made with the class corresponding to the column for examples with the correct value as represented by the row. Thus, the diagonal elements show the number of correct classifications made for each class, and the off-diagonal elements show the errors made.