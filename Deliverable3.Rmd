---
title: "Deliverable 3"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA","MASS")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
if(Sys.info()[[4]]=="PORT_ELISABET"){
  setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")
}else{
  setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
}

#rm(list=ls())
load("data-INI2.RData")
```

# Modelización con target numérico

## Modelización con variables explicativas numéricas

### Modelo simple

El primer paso es decidir con cuantas variables contamos para el modelo. Si tuviéramos muchas variables explicativas podríamos utilizar el resultado del condes para saber cuáles de ellas utilizar, aunque también sería posible seleccionarlas a partir del análisis de componentes principales. Dado que tenemos poca cantidad de variables usamos todas.   

Empezamos utilizando lm para crear un modelo inicial del cual podemos ir descartando aquellas variables explicativas que nos parecen irrelevantes. Después contrastaremos nuestra selección usando el método Akaike o BIC, que en una sucesión de pasos va descartando variables.

```{r}
# chunk 10
m1<-lm(duration~.,data=df[,c("duration",vars_num)])
summary(m1)
Anova(m1)
```

Viendo este volcado, vemos que todas las variables menos, campaign tienen un p-value superior al 0.05, sin embargo, pdays y previous están por debajo de 0.1 lo que podríamos llegar a incorporarlas al modelo. El r-square es de 0.006393 lo que nos dice que nuestro modelo no se ajusta bien.

Al ver el resultado de Anova, podemos ver resultados muy parecidos.

Ahora probaremos seleccionando las variables a partir de la criba anterior: #preguntar diferencia summary y Anova, sabemos que el Anova nos dice para cada variable la probabilidad de que el modelo sea igual con o sin esta variable mediante el p-value, entonces que nos dice el summary de diferente?

```{r}
# chunk 20
m2<-lm(duration~campaign+pdays+previous,data=df)
summary(m2)
Anova(m2)

m3<-lm(duration~campaign+pdays,data=df)
summary(m3)
Anova(m3)
vif(m3)

par(mfrow=c(2,2))
plot(m3)
par(mfrow=c(1,1))
m=m3;
```

Viendo el resultado del lm con estas variables, podemos ver que previous da por encima de 0.2, por lo que también descartamos esta variable. También podemos ver que el r-square sigue siendo muy bajo.

Al realizar nuevamente el lm con estas dos variables restantes, vemos que su p-value es inferior al 0.1, por lo que daríamos por concluida la criba.

Finalmente hacemos el análisis de residuos con vif, el cual  nos dice si existen problemas de colinealidad es decir si existen variables que pueden explicar a otras. Si nos da valores por debajo de 3 son buenos y por encima de 5 que las variables elegidas tienen redundancia y que inflará las varianzas. En nuestro caso, el resultado de las dos variables es inferior a 3.

Viendo el plot de la normal Q-Q, vemos que los valores distan mucho de la recta de referencia, con que podemos decir que su distribución no es para nada normal.


Ahora procederemos a comprobar el resultado usando la función step, conocida como Akaike o BIC.

```{r}
# chunk 30
m4<-step(m)
```
Al aplicar el metodo step, vemos que no hace niguna criba más y se queda con el mismo modelo que ya nosotros habiamos cribado. 


Si probamos con la versión bayesiana (del BIC):
```{r}
# chunk 40
m5<-step(m,k=log(nrow(df)))
summary(m5)
par(mfrow=c(2,2))
plot(m5)
par(mfrow=c(1,1))
```

La versión bayesiana es conveniente usarla en casos de muestras grandes. En este caso vemos que se queda con una sola variable (campaign), ya que en el primer step del volcado vemos que sin la variable p-days el valor AIC, en este caso BIC, es menor.

En este caso no podemos hacer el análisis de residuos con vif porque solo tenemos 1 variable.

Al igual que en nuestro caso nos da una plot Q-Q totalmente desviada de las dist normal.

### Modelo con transformaciones

Mediante la función boxcox descartamos la posibilidad de elevar el target al cuadrado, pero sí contemplamos aplicarle el logaritmo, pues el pico de la curva está entre 0 y 1, bastante cerca del 0.
```{r}
# chunk 50
boxcox(m,data=df)
```

Ahora procedemos a la transformación polinómica.  

Como solo tenemos una variable explicativa podemos empezar desde cero pero si tuviéramos ya un modelo no volveríamos a empezar.
```{r}
# chunk 60
m6<-lm(log(duration)~.,data=df[,c("duration",vars_num)]) 
Anova(m6)
```

Viendo el resultado del Anova, procedemos a descartar las variables cuyo valor de Pr es mayor a 0.1

```{r}
# chunk 70
m7<-lm(log(duration)~campaign+pdays+nr.employed,data=df)
summary(m7)
Anova(m7)

par(mfrow=c(2,2))
plot(m7)
par(mfrow=c(1,1))
```
Viendo los p-values, nos encontramos que la variable nr.employed es mayor a 0.1, por lo que procedemos a eliminarla de nuestro modelo.

Relativo al gráfico, podemos ver como la Normal Q-Q ha mejorado bastante acercándose a la recta ideal.

Ahora procedemos a quitar nr.employed.
```{r}
# chunk 80
m9<-lm(log(duration)~campaign+pdays,data=df)
summary(m9)
Anova(m9)
vif(m9)

par(mfrow=c(2,2))
plot(m9)
par(mfrow=c(1,1))
```
Viendo el valor final del r-square, podemos ver que este no es un buen modelo. También los que no puede decir es que las variables no representan a nuestro target, esto ya lo pudimos ver en el deliverable2.

El resultado del vif nos da valores aceptables, diciendo que no hay colinealidad entre variables.

### Modelo de regresión polinómica

Ahora podemos probar con las versiones cuadráticas de las variables explicativas, partiendo de nuestro mejor modelo:
```{r}
# chunk 90
m20<-lm(log(duration)~poly(campaign,2)+poly(pdays,2),data=df)
summary(m20)
Anova(m20)
vif(m20)
par(mfrow=c(2,2))
plot(m20)
par(mfrow=c(1,1))
influencePlot(m20)
marginalModelPlots(m20)
```
#pregunta la validacion la podemos hacer aqui o debe ser al final de este bloque.
Analizando los gráficos:   
  - Residual VS Fitted. En este gráfico muestra los residuos de los valores predecidos. Lo deseable es que los puntos estén uniformemente dispersos, para poderlo contrastar el gráfico esta provisto de una recta smoother que conviene que sea horizontal, y uniforme. En nuestro caso el resultado es aceptable.  
  - Normal Q-Q.  Este plot nos muestra la tendencia a una distribución normal de los residuos, esta provista de una recta diagonal de referencia en la que se espera que los residuos se ajusten lo máximo posible. En nuestro caso, apreciamos ciertas desviaciones en los extremos de la recta, aunque si lo comparamos con plots anteriores, es una recta bastante aceptable.  
  - Scale-Location. Este plot hace referencia a la varianza de los valores de la predicción, si se mantiene constante implica homocedasticidad, de lo contrario heterocedasticidad que se vería reflejada en una nube de puntos en forma de cono. Para nuestro caso, podemos ver que el gráfico tiene una tendencia a cono que además se evidencia con la desviación de la smoother line.  
  - Residuals Vs Leverage.   # preguntar, no vemos las curvas de nivel en el grafico, y como se ven reflejadas las observaciones influyentes, y que significa que el leverage sea el factor de anclaje.
  - InfluenPLot. Nos muestra las individuos más influentes, esto se puede ver gráficamente a través del radio de las circunferencias. En nuestro caso, viendo el gráfico podemos ver que no hay niguna que sea excesivamente influente.  
  - MarginalModelPlot. Nos muestra las discrepancias entre las predicciones de nuestro modelo y los resultados reales de nuestras observaciones desglosado por variables, utiliza dos líneas de soporte, una roja para la tendencia del modelo y otra azul referente a cada variable. #preguntar el resultado del grafuco, que en el primero la linea azul cae en picada al final

Trabajamos con el mejor modelo obtenido, y vemos que individuos influyen más en nuestros datos para saber si están afectando nuestro resultado.
```{r}
# chunk 100
matplot(dfbetas(m9), type="l", col=2:4,lwd=2)
Boxplot(cooks.distance(m9)) #preguntar nos sale el 3660 pero en el grafico anterior no sale, porque? y si hay que quitarlo al final, porque al final?
```
Consideramos que hay un individuo que repercute demasiado en los datos, aún así no lo eliminaremos hasta el final.

## Modelización con variables explicativas numéricas y categóricas

Creamos una variable que contiene las variables categóricas y categóricas factorizadas además de las categóricas.
```{r}
# chunk 110
vars_cat_total = c(vars_cat, names(df[,22:29]))
condes(df[,c("duration",vars_cat_total)],1, proba= 0.01)
```
Al hacer condes, con todas las variables categóricas, contemplamos el uso de f.campaign y month para nuestro modelo, ya que la probabilidad de que no tengan relación con el target está por debajo del 0.01. Como nos sale la versión categórica de campaign que también nos sale en el modelo númerico, debemos elegir entre una u otra pero nunca las dos a la vez.  

En vista de que la variable numérica pdays aporta una información errante ya que aquellos que no fueron contactados tienen asignados un valor que no les corresponde, decidimos utilizar f.pdays porque contiene una información más rigurosa, ya que se clasifican entre contactados y no contactados.  

Contrastamos un modelo con campaign o con f.campaign para ver cual es mejor.

```{r}
# chunk 120
m22<-lm(log(duration)~campaign+f.pdays+month,data=df)
m23<-lm(log(duration)~f.pdays+f.campaign+month,data=df)
BIC(m23,m22)

# Ya que nos quedamos con el modelo m22
Anova(m22)
```

Haciendo BIC para comparar modelos, podemos ver que el que da un menor BIC es m22, por lo que decidimos quedarnos con este modelo.
Viendo el resultado del Anova, podemos ver que los p-values son inferiores a 0.1

## Interacciones

#preguntar que significa hacer interaccion entre factor y covariate (esta en el enunciado tercer titulo en negritas).
#preguntar se debe hacer asi? comparando el modelo con el step. Porque? cual cogemos usando el anova.
```{r}
# chunk 130
m30<-lm(log(duration)~(campaign+f.pdays+month)^2,data=df)
summary(m30)
m31<-step(m30,k=log(nrow(df)))
Anova(m31)
anova(m31,m30) # Fisher test - Priority to BIC criteria

```

## Validación

```{r}
# chunk 140
par(mfrow=c(2,2))
plot(m30)
par(mfrow=c(1,1))
```
1- Residual Vs Fitted: Viendo la gráfica podemos ver que 
2- Normal Q-Q: No se asemeja a la recta normal.
3- Scale-Location: Parece ser un poco homocedastica
4- Residual Vs Leverage:


# Modelización con target binario

Empezamos dividiendo nuestra muestra en una muestra de trabajo y una muestra de testeo, para ello seleccionaremos aleatoriamente el 25% de la muestra para crear la muestra de testeo.

```{r}
# chunk 150
set.seed(19101990)
sam <-sample(1:nrow(df),0.75*nrow(df)) 

dfw<-df[sam,]
dft<-df[-sam,]

```

## Modelización con variables explicativas numéricas


Para empezar hacemos un catdes con todas las variables númericas para ver cuales son las que están más relacionadas con nuestro target.
Las ultilizamos para hacer un modelo lineal general con variables explicativas numéricas. Este modelo es de la familia binomial ya que nuestro target es binario.
```{r}
# chunk 160
catdes(dfw[,c("y",vars_num,"duration")],1) #pregunar hay que poner duration??  hay que poner todas las variables? nos salen con pvalue bajo
gm1<-glm( y ~ 
            duration +
            nr.employed +
            pdays +
            euribor3m +
            emp.var.rate +
            previous +
            cons.price.idx +
            campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw)
summary(gm1)

#preguntar se puede usar el step?
#preguntar, no es necesario Anova aqui? cual es el mas indicado summary o Anova
```

Viendo el resultado de summary, podemos ver variables que tienen el p-value mayor a 0.1 (cons.cinf.idx, euribor3m), por lo que procedemos a quitarlas de nuestro modelo. 
Podemos ver que el deviance es inferior al null deviance.

```{r}
# chunk 170
gm2<-glm( y ~ 
            duration +
            nr.employed +
            pdays +
            emp.var.rate +
            previous +
            campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw)
vif(gm2)
```

Haciendo vif podemos ver que emp.var.rate tiene un valor mayor a 3, por lo que decidmos sacarla de nuestro modelo.

```{r}
# chunk 180
gm3<-glm( y ~ 
            duration +
            nr.employed +
            pdays +
            previous +
            campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw)
vif(gm3)
```


### Modelo simple
### Modelo con transformaciones
### Modelo de regresión polinómica
## Modelización con variables explicativas numéricas y categóricas
## Interacciones
## Validación


#preguntar en que momento quitar esta observacion
```{r}
# Sin el individuo que más afecta
 m9m<-lm(log(duration)~campaign+pdays,data=df[-3660,]) # ACORDARNOS DE MOVERLO AL FINAL - se deberia eliminar al final de todo no aqui, ya que al final tendremos todos los datos
Boxplot(cooks.distance(m9m))
coef(m9m)
```





