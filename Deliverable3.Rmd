---
title: "Deliverable 3"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA","MASS")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
#setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")

rm(list=ls())
load("data-INI2.RData")
```


# Y (Numeric Target). This variable will be the target for linear model building (connected to blocks Statistical Modeling I and II).

## Explicative Variables for modeling purposes are generally (not all in this dataset):

    * Socioeconomic variables: gender, age, education, type of work, etc
    * Activity in the current commercial campaign
    * Bank marketing history
    * Economic vars

## Multivariant Analysis conducted in previous deliverables has to be used to select the initial model. Students have some degrees in freedom in model building, but the following conditions are requested:

    * At least two numerical variables have to be considered as explicative variables for initial steps in model building, called covariates. Non-linear models have to be checked for consistency.
    * Select the most significant factors found in Multivariant Data Analysis as initial model factors.  Put some reasonable limits to initial model complexity.
    * You have to consider at least one interaction between a couple of factors and one interaction between factor and covariate.
    * Diagnostics of the final model have to be undertaken. Lack of fit observations and influence data have to be selected and discussed (connections to multidimensional outliers in Multivariant Data Analysis is highly valuable)
    
# Clasificación de las variables (modeling I y II).
    *   Variable Target "duration"
    *   Socio económicas: age, job, marital, education, default, housing, loan
    *   Activity in the current commercial campaign: Month, day of the week, duration, campaing, pdays, previous.  
    *   Bank marketing history: pdays, previous, poutcome.
    *   Economic vars: emp.var.rate, cons.price.index, cons.conf.index, euribor3m, number employed.

El primer paso es decidir con cuantas variables contamos para el modelo. Si tuvieramos muchas variables explicativas podriamos utilizar el resultado del condes para saber cuáles de ellas utilizar, aunque también sería posible seleccionarlas a partir del análisis de componentes principales. Dado que tenemos poca cantidad de variables usamos todas. Empezamos utilizando lm para crear un modelo inicial del cual podemos ir descartando aquellas variables explicativas que nos parecen irrelevantes. Después contrastaremos nuestra selección usando el método Akaike o BIC, que en una sucesión de pasos va descartando variables.

```{r}
# chunk 10
m1<-lm(duration~.,data=df[,c("duration",vars_num)])
summary(m1)
Anova(m1)
```

Viendo este volcado, vemos que todas las variables menos, campaign tienen un p-value superior al 0.05, sin embargo, pdays y previous estan por debajo de 0.1 lo que podriamos llegar a incorporarlas al modelo. El r-square es de 0.006393 lo que nos dice que nuestro modelo no se ajusta bien.

# preguntar (que es r-square, que si es la suma de cuadrados de los residuos, esta debe ser cuanto menos mejor??) : multiple r-qsuare porque esta elevado al cuadrado, R:multiple R que quiere decir de la correlacon que tiene nuestro target con las predicciones de un modelo, eso seria el multple r. R^2=cor^2(y,y^y), Minetras el r-square es mayor quiere decir que nuestro modelo se ajusta bien por lo que es bueno, tiende a 1. No es importante si es negativo, lo que importa es la correlacion y ya esta. El ser negativo es irrelevante.  
#nos interesa que RSS sea lo mas pequeño posible y eso sera cuando la R2 sea lo mas grande posible. TSS(Total sum squares) este es con la mediana muestral del target, que se puede dividir por n si se quiere saber la variabilidad del target, da como resultado una estimacion de la varianza del target. Un estimador de una varianza de una variable sera esto.
# TSS = RSS(Nos interesa que sea muy prqueño para que nuestro modelo sea grande y quiere decir que el modelo es bueno) + ESS(Suma de cuadrados explicada. )-> esto es una suma de cuadrados que se tiene explicado en los slides de teoria.  El TSS esta relacionado con la variabilidad del target, el target debemos explicarlo con un modelo que nos..
# la formula y=Xb+E es importante para explicar el modelo. El epsilon es la parte residual que no esta en el modelo (es el residuo? si y no, tecnicamente no, pero conceptualmente si) esta formula se interpreta de forma conceptual0



Al ver el resultado de Anova, podemos ver resultados muy parecidos preguntar (diferencia de Anova y summary, ya que nos dan Pr prácticamente iguales)
# En estos casos no hay diferencia, pero en otros modelos como el de poly da diferentes de la clase del 3, el m20. En este caso es dif porque hay variables explicaticas que ponems en el modelo. Por ejemplo para ese estamos usando em.var.rate como pol. El metodo Anova si identifica que estas dos var estan relacionadas.(algo asi) el summary no lo podemos mirar si tenemos variables explicativas de factores.

# funcon predict para tener resultados dado un modelo.

Ahora probaremos selecionando las variables a partir de la criba anterior:

```{r}
# chunk 20
m2<-lm(duration~campaign+pdays+previous,data=df)
summary(m2)
Anova(m2)

m3<-lm(duration~campaign+pdays,data=df)
summary(m3)
Anova(m3)
# tomar decision con el step si quedamos con estas variables no. congraciar los dis puntos de vista del step y estte
vif(m3)

par(mfrow=c(2,2))
plot(m3)
par(mfrow=c(1,1))

m=m3;
```

Viendo el resultado del lm con estas variables, podemos ver que previous da por encima de 0.2, por lo que también descartamos esta variable. Tambien podemos ver que el r-square sigue siendo muy bajo.

Al realizar nuevamente el lm con estas dos variables restantes, vemos que su p-value es inferior al 0.1, por lo que daríamos por concluida la criba.

Finalmente hacemos el análisis de residuos con vif, el cual nos dice que si nos da valores por debajo de 3 son buenos y por encima de 5 que las variables elegidas tienen redundancia y que inflará las varianzas. En nuestro caso, el resultado de las dos variables es inferior a 3.

Viendo el plot de la normal Q-Q, vemos que los valores distan mucho de la recta de referencia, con que podemos decir que su distribución no es para nada normal.


Ahora procederemos a comprobar el resultado usando la función step, conocida como Akaike o BIC.

```{r}
# chunk 30
m4<-step(m1)
vif(m4)
summary(m4)
par(mfrow=c(2,2))
plot(m4)
par(mfrow=c(1,1))
```

En contraste a nuestra selección (pdays y campign), Akaike ha decidido conservar 5 variables. Aún así, podemos ver que el Akaike ha conservado las dos variables que nosotros hemos decidido dejar.

Hacemos el análisis de residuos con vif. En nuestro caso, el resultado de las 5 variables es inferior a 3. Al igual que en nuestro caso nos da una plot Q-Q totalmente desviada de las dist normal.

Si probamos con la versión bayesiana (del BIC):
```{r}
# chunk 40
m5<-step(m1,k=log(nrow(df)))
summary(m5)
par(mfrow=c(2,2))
plot(m5)
par(mfrow=c(1,1))
```

La versión bayesiana es conveniente usarla en casos de muestras grandes. En este caso vemos que se queda con una sola variable (campaign).

En este caso no podemos hacer el análisis de residuos con vif porque solo tenemos 1 variable.

Al igual que en nuestro caso nos da una plot Q-Q totalmente desviada de las dist normal.


Mediante la función boxcox descartamos la posibilidad de elevar el target al cuadrado, pero sí contemplamos aplicarle el logaritmo, pues el pico de la curva está entre 0 y 1 y bastante cerca del 0.
```{r}
# chunk 50
boxcox(m,data=df)  #lambda 0 <- log(Y)
# se hace a partir de u cierto modelo, es informativo. En nuestr caso particular podemos empezar oc el boxcox
```


Ahora procedemos a la transformación polinómica:
```{r}
# chunk 60
m6<-lm(log(duration)~.,data=df[,c("duration",vars_num)]) # como solo tenemos dos variables explicativas podemos empezar desde cero pero si tuvieramos ya n modelo no volvieramos a empezar
# m6<-lm(log(duration)~campaign+pdays,data=df)
Anova(m6)
```

Viendo el resultado del Anova, procedemos a descartar las variables cuyo valor de Pr es mayor a 0.1

```{r}
# chunk 70
m7<-lm(log(duration)~campaign+pdays+nr.employed+euribor3m,data=df)
summary(m7)
Anova(m7)
vif(m7)

par(mfrow=c(2,2))
plot(m7)
par(mfrow=c(1,1)) # problema de escala en standar resd pero como ya esta la variable transsformada no se pued hacer mas
```
Al hacer vif, podemos ver que nr.employed y euribor3m, tienen valores mayores de 5, lo que nos dice que hay redundancia entre estas variables por lo que procedemos a quitar la que tiene mayot Pr (euribor3m).

Relativo al grafico, podemos ver como la Normal Q-Q ha mejorado bastante acercandose a la recta ideal.

```{r}
# chunk 80
m8<-lm(log(duration)~campaign+pdays+nr.employed,data=df)
summary(m8)
Anova(m8)
vif(m8)

par(mfrow=c(2,2))
plot(m8)
par(mfrow=c(1,1)) # problema de escala en standar resd pero como ya esta la vatiable transsformada no se pued hacer mas
```
Ahora al hacer vif con las nuevas variables vemos que los valores dan menores de 3, pero el Pr de employed es mayor a 0.1, por que decidimos a sacarla.

No se ve mucha diferencia respecto a el grafico de m7.

Ahora procedemos quitando nr.employed.
```{r}
# chunk 90
m9<-lm(log(duration)~campaign+pdays,data=df)
summary(m9)
Anova(m9)
vif(m9)

par(mfrow=c(2,2))
plot(m9)
par(mfrow=c(1,1))
```
Viendo el valor final del r-square, podemos ver que este no es un buen modelo. Tambien los que no puede decir es que las variables no representan a nuestro target, estoy ya lo pudimos ver en el deliverable2.


Ahora podemos probar con las versiones cuadráticas de las variables explicativas:
```{r}
# chunk 100
m20<-lm(log(duration)~poly(campaign,2)+poly(pdays,2),data=df)
summary(m20)
Anova(m20)
vif(m20)
par(mfrow=c(2,2))
plot(m20)
par(mfrow=c(1,1))
# la duration no teiene nada que ver ocn las numericas
```

# practica en  influent data, para estar seguros que el tema del diagnostico, hacer diagnotistico, residual plot, marginal plot, influence plot, porque en algun moemtno hay que hacerlo, se ha explicado esta semana.

# falta introducir todos los factores y repetir los procesos, falta mucho.
# podemos avanzar mas en sentirnos comodos en analisis de datos influentes.
# el analisis se hacee s al final cuando se tienen todas las caiables posibles unericas y factores.


## Multivariant Analysis conducted in previous deliverables has to be used to select the initial model. Students have some degrees in freedom in model building, but the following conditions are requested:


	* Select the most significant factors found in Multivariant Data Analysis as initial model factors.  Put some reasonable limits to initial model complexity.
	* You have to consider at least one interaction between a couple of factors and one interaction between factor and covariate.
	* Diagnostics of the final model have to be undertaken. Lack of fit observations and influence data have to be selected and discussed (connections to multidimensional outliers in Multivariant Data Analysis is highly valuable)


Trabajamos con el mejor modelo obtenido, y vemos que individuos influyen más en nuestros datos para saber si estan afectando nuestro resultado.
```{r}
# chunk 110
matplot(dfbetas(m9), type="l", col=2:4,lwd=2)
Boxplot(cooks.distance(m9))
coef(m9)

# Sin los individuos que más afectan 
m9m<-lm(log(duration)~campaign+pdays,data=df[-3660,]) # se deberia eliminar al final de todo no aqui, ya que al final tendremos todos los datos
Boxplot(cooks.distance(m9m))
coef(m9m)
```
Consideramos que hay un individuo que repercute demasiado en los datos, aún así no lo eliminaremos hasta el final.


```{r}
# chunk 120
vars_cat_total = c(vars_cat, names(df[,22:29])) # creamos una vars_cat con las  categorias factorizadas
condes(df[,c("duration",vars_cat_total)],1, proba= 0.01)
```
Al hacer condes, con todas las variables categoricas, contemplamos el uso de f.duration, f.campaign, months, para nuestro modelo ya que la probabilidad de que no tengan relaión con el target esta por debajo del 0.01.

# Outcome/Target : A binary response variable (Binary Target) will be the response variable for Binary Regression Models included in Statistical Modeling Part III.

Explicative Variables for modeling purposes are those available in dataset, exceptions will be indicated, if any.

Multivariant Analysis conducted in previous deliverables has to be used to select the initial model. Students have some degrees in freedom in model building, but the following conditions are requested:

    * Split the sample in work and test samples (consisting on a 80-20 split). Working data frame has to be used for model building purposes.

    *At least two numerical variables have to be considered as explicative variables for initial steps in model building.
    *Select the most significant factors according to feature selection as initial model factors.  Put some reasonable limits to initial model complexity.
    *You have to consider at least one interaction between a couple of factors and one interaction between factor and covariate.
    *Diagnostics of the final model have to be undertaken. Lack of fit observations and influence data have to be selected and discussed (connections to multidimensional outliers in Multivariant Data Analysis is highly valuable).
    *You have to predict Y (Binary Target)  in the Working Data Frame  vs the rest according to the best validated model that you can find and make a confusion matrix.
    *Make a confusion matrix in the Testing Data Frame for  Y  (Binary Target) according to the best validated model found.

```{r}
#en clase
  
```



Confusion Matrix: When referring to the performance of a classification model, we are interested in the modelâs ability to correctly predict or separate the classes. When looking at the errors made by a classification model, the confusion matrix gives the full picture. Consider e.g. a three class problem with the classes A, and B. The confusion matrix shows how the predictions are made by the model. The rows correspond to the known class of the data, i.e. the labels in the data. The columns correspond to the predictions made by the model. The value of each of element in the matrix is the number of predictions made with the class corresponding to the column for examples with the correct value as represented by the row. Thus, the diagonal elements show the number of correct classifications made for each class, and the off-diagonal elements show the errors made.