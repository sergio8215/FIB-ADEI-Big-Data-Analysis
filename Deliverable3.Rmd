---
title: "Deliverable 3"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA","MASS")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
if(Sys.info()[[4]]=="PORT_ELISABET"){
  setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")
}else{
  setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
}

rm(list=ls())
load("data-INI2.RData")
```

# Modelización con target numérico

## Modelización con variables explicativas numéricas

### Modelo simple

El primer paso es decidir con cuantas variables contamos para el modelo. Si tuviéramos muchas variables explicativas podríamos utilizar el resultado del condes para saber cuáles de ellas utilizar, aunque también sería posible seleccionarlas a partir del análisis de componentes principales. Dado que tenemos poca cantidad de variables usamos todas.   

Empezamos utilizando lm para crear un modelo inicial del cual podemos ir descartando aquellas variables explicativas que nos parecen irrelevantes. Después contrastaremos nuestra selección usando el método Akaike o BIC, que en una sucesión de pasos va descartando variables.

```{r}
# chunk 10
m1<-lm(duration~.,data=df[,c("duration",vars_num)])
summary(m1)
Anova(m1)
```

Viendo este volcado, vemos que todas las variables menos, campaign tienen un p-value superior al 0.05, sin embargo, pdays y previous están por debajo de 0.1 lo que podríamos llegar a incorporarlas al modelo. El r-square es de 0.006393 lo que nos dice que nuestro modelo no se ajusta bien.

Al ver el resultado de Anova, podemos ver resultados muy parecidos.

Ahora probaremos seleccionando las variables a partir de la criba anterior:

```{r}
# chunk 20
m2<-lm(duration~campaign+pdays+previous,data=df)
summary(m2)

m3<-lm(duration~campaign+pdays,data=df)
summary(m3)
vif(m3)

par(mfrow=c(2,2))
plot(m3)
par(mfrow=c(1,1))
m=m3;
```

Viendo el resultado del lm con estas variables, podemos ver que previous da por encima de 0.2, por lo que también descartamos esta variable. También podemos ver que el r-square sigue siendo muy bajo.

Al realizar nuevamente el lm con estas dos variables restantes, vemos que su p-value es inferior al 0.1, por lo que daríamos por concluida la criba.

Finalmente hacemos el análisis de residuos con vif, el cual  nos dice si existen problemas de colinealidad es decir si existen variables que pueden explicar a otras. Si nos da valores por debajo de 3 son buenos y por encima de 5 que las variables elegidas tienen redundancia y que inflará las varianzas. En nuestro caso, el resultado de las dos variables es inferior a 3.

Viendo el plot de la normal Q-Q, vemos que los valores distan mucho de la recta de referencia, con que podemos decir que su distribución no es para nada normal.

Para quitar las variables redundantes probamos con la versión bayesiana del step (del BIC):
```{r}
# chunk 40
m5<-step(m,k=log(nrow(df)))
summary(m5)
par(mfrow=c(2,2))
plot(m5)
par(mfrow=c(1,1))
```

La versión bayesiana es conveniente usarla en casos de muestras grandes. En este caso vemos que se queda con una sola variable (campaign), ya que en el primer step del volcado vemos que sin la variable p-days el valor AIC, en este caso BIC, es menor.

En este caso no podemos hacer el análisis de residuos con vif porque solo tenemos 1 variable.

Al igual que en nuestro caso nos da una plot Q-Q totalmente desviada de las dist normal.

### Modelo con transformaciones

Mediante la función boxcox descartamos la posibilidad de elevar el target al cuadrado, pero sí contemplamos aplicarle el logaritmo, pues el pico de la curva está entre 0 y 1, bastante cerca del 0.
```{r}
# chunk 50
boxcox(m,data=df)
```

Ahora procedemos a la transformación polinómica.  

Como solo tenemos una variable explicativa podemos empezar desde cero pero si tuviéramos ya un modelo no volveríamos a empezar.
```{r}
# chunk 60
m6<-lm(log(duration)~.,data=df[,c("duration",vars_num)]) 
Anova(m6)
```

Viendo el resultado del Anova, procedemos a descartar las variables cuyo valor de Pr es mayor a 0.1

```{r}
# chunk 70
m7<-lm(log(duration)~campaign+pdays+nr.employed,data=df)
summary(m7)
Anova(m7)
```
Viendo los p-values, nos encontramos que la variable nr.employed es mayor a 0.1, por lo que procedemos a eliminarla de nuestro modelo.

Relativo al gráfico, podemos ver como la Normal Q-Q ha mejorado bastante acercándose a la recta ideal.

Ahora procedemos a quitar nr.employed.
```{r}
# chunk 80
m9<-lm(log(duration)~campaign+pdays,data=df)
summary(m9)
Anova(m9)
vif(m9)
```
Viendo el valor final del r-square, podemos ver que este no es un buen modelo. También los que no puede decir es que las variables no representan a nuestro target, esto ya lo pudimos ver en el deliverable2.

El resultado del vif nos da valores aceptables, diciendo que no hay colinealidad entre variables.

### Modelo de regresión polinómica

Ahora podemos probar con las versiones cuadráticas de las variables explicativas, partiendo de nuestro mejor modelo:
```{r}
# chunk 90
m20<-lm(log(duration)~poly(campaign,2)+poly(pdays,2),data=df)
summary(m20)
Anova(m20)
vif(m20)
par(mfrow=c(2,2))
plot(m20)
par(mfrow=c(1,1))

```


## Modelización con variables explicativas numéricas y categóricas

Creamos una variable que contiene las variables categóricas y categóricas factorizadas además de las categóricas.
```{r}
# chunk 110
vars_cat_total = c(vars_cat, names(df[,22:29]))
condes(df[,c("duration",vars_cat_total)],1, proba= 0.05)
```
Al hacer condes, con todas las variables categóricas, contemplamos el uso de f.campaign y month para nuestro modelo, ya que la probabilidad de que no tengan relación con el target está por debajo del 0.01. Como nos sale la versión categórica de campaign que también nos sale en el modelo númerico, debemos elegir entre una u otra pero nunca las dos a la vez.  

En vista de que la variable numérica pdays aporta una información errante ya que aquellos que no fueron contactados tienen asignados un valor que no les corresponde, decidimos utilizar f.pdays porque contiene una información más rigurosa, ya que se clasifican entre contactados y no contactados. 

Debido a que la variable month es una variable con muchos niveles y eso no es bueno para la modelización, decidimos reagruparla.

```{r}
#chunk 115
# Months to groups
df$f.influentMonth <- 3
# 1 level - mar-may 
aux<-which(df$month %in% c("month.apr","month.jun","month.aug"))
df$f.influentMonth[aux] <-1

# 2 level - jun-ago
aux<-which(df$month %in% c("month.sep","month.may","month.jul"))
df$f.influentMonth[aux] <-2

# 3 level - aug-feb
aux<-which(df$month %in% c("month.mar","month.dec","month.oct","month.nov"))
df$f.influentMonth[aux] <-3

df$f.influentMonth<-factor(df$f.influentMonth,levels=1:3,labels=c("apr-jun-aug","sep-may-jul","mar-dec-oct-nov"))
levels(df$f.influentMonth)<-paste0("f.influentMonth.",levels(df$f.influentMonth)) # Hacemos las etiquetas m?s informativas
summary(df$f.influentMonth)

```


Contrastamos un modelo con campaign o con f.campaign para ver cual es mejor.

```{r}
# chunk 120
m22<-lm(log(duration)~campaign+f.pdays+f.influentMonth,data=df)
m23<-lm(log(duration)~f.pdays+f.campaign+f.influentMonth,data=df)
BIC(m23,m22)

# Ya que nos quedamos con el modelo m22
Anova(m22)
```

Haciendo BIC para comparar modelos, podemos ver que el que da un menor BIC es m22, por lo que decidimos quedarnos con este modelo.
Viendo el resultado del Anova, podemos ver que los p-values son inferiores a 0.1

## Interacciones

```{r}
# chunk 130
m30<-lm(log(duration)~(campaign+f.pdays+f.influentMonth)^2,data=df)
Anova(m30)
```
Vemos que la interacción entre campaign y nuestra nueva variable factor month es significativa, por lo tanto creamos un nuevo modelo m31 con esa interacción. Por otro lado aunque f.pdays con f.influentMoth tiene un p-value muy alto de 0.4, realizamos la interacción porque lo pide el enunciado.

```{r}
#chunk 140
m31<-lm(log(duration)~(f.influentMonth*campaign+f.pdays),data=df)
Anova(m31)

m32<-lm(log(duration)~(f.influentMonth*f.pdays+campaign),data=df)
Anova(m32)

```
Vemos que el modelo 31 es aceptable, sus p-values son aceptables, mientras como ya era previsible el modelo m32 lo descartamos.

## Validación

```{r}
# chunk 140
par(mfrow=c(2,2))
plot(m31)
par(mfrow=c(1,1))
residualPlots(m31)
```


Analizando los gráficos:   
  - Residual VS Fitted. En este gráfico muestra los residuos de los valores predecidos. Lo deseable es que los puntos estén uniformemente dispersos, para poderlo contrastar el gráfico esta provisto de una recta smoother que conviene que sea horizontal, y uniforme. A pesar de que podemos ver un patrón en el gráfico, podemos decir que el resultado no es aceptable.
  - Normal Q-Q.  Este plot nos muestra la tendencia a una distribución normal de los residuos, esta provista de una recta diagonal de referencia en la que se espera que los residuos se ajusten lo máximo posible. En nuestro caso, apreciamos ciertas desviaciones en los extremos de la recta, aunque si lo comparamos con plots anteriores, se acerca más a la normal, pero sigue siendo poco aceptable.  
  - Scale-Location. Este plot hace referencia a la varianza de los valores de la predicción, si se mantiene constante implica homocedasticidad, de lo contrario heterocedasticidad que se vería reflejada en una nube de puntos en forma de cono. Para nuestro caso, podemos ver que el gráfico tiene una tendencia a cono que además se evidencia con la desviación de la smoother line. Pero es una heterocedasticidad que es imposible de corregir de manera fácil, es una replica del primer plot.
  
  - Residuals Vs Leverage.   #preguntar otra vez.... preguntar, no vemos las curvas de nivel en el grafico, y como se ven reflejadas las observaciones influyentes, y que significa que el leverage sea el factor de anclaje.... lo podemos mirar en las transparencias de teoria 5 4 o 3 veces la mediana del leverage, hay que dibujarlo o valorarlo de alguna maeraa , hacer el influence polot que nos dara la distancia de coolk(ya esta hecho)
  
  - ResidualPlot.
  

```{r}
#chunk 150
influencePlot(m31)
marginalModelPlots(m31)
which(row.names(df)==27860)
which(row.names(df)==27553)
```

  - InfluenPLot. Nos muestra las individuos más influentes, esto se puede ver gráficamente a través del radio de las circunferencias. En nuestro caso, viendo el gráfico podemos ver que hay individuos bastante influyentes, el 3329 y 3293 que para nuestra muestra serian los individuos.
  - MarginalModelPlot. Nos muestra las discrepancias entre las predicciones de nuestro modelo y los resultados reales de nuestras observaciones desglosado por variables, utiliza dos líneas de soporte, una roja para la tendencia del modelo y otra azul referente a cada variable. Podemos ver que para nuestros dis gráficos #preguntar, solo se puede usar para variabls numericas?? podemos usarlo aqui donde la unica variable numerica es campaign?? 

Trabajamos con el mejor modelo obtenido, y vemos que individuos influyen más en nuestros datos para saber si están afectando nuestro resultado.
```{r}
# chunk 160
matplot(dfbetas(m31), type="l", col=2:4,lwd=2)
Boxplot(cooks.distance(m31))
```
Consideramos que hay un individuo que repercute demasiado en los datos (3293), aún así no lo eliminaremos.


```{r}
#chunk 170  
# Sin el individuo que más afecta

m9m<-lm(log(duration)~(f.influentMonth*campaign+f.pdays),data=df[c(-3293,-3290,-3329),]) # ACORDARNOS DE MOVERLO AL FINAL - se deberia eliminar al final de todo no aqui, ya que al final tendremos todos los datos
Boxplot(cooks.distance(m9m))
summary(m9m)
summary(m31)
```
Podemos ver que el nuevo modelo sin los individuos influyentes tiene una mejora en el r-square, aunque este sigue siendo muy bajo.

# Modelización con target binario

Empezamos dividiendo nuestra muestra en una muestra de trabajo y una muestra de testeo, para ello seleccionaremos aleatoriamente el 25% de la muestra para crear la muestra de testeo.

```{r}
# chunk 150
set.seed(19101990)
sam <-sample(1:nrow(df),0.75*nrow(df)) 

dfw<-df[sam,]
dft<-df[-sam,]

```

## Modelización con variables explicativas numéricas

### Modelo simple

Para empezar hacemos un catdes con todas las variables númericas para ver cuales son las que están más relacionadas con nuestro target.
Las ultilizamos para hacer un modelo lineal general con variables explicativas numéricas. Este modelo es de la familia binomial ya que nuestro target es binario.
```{r}
# chunk 160
catdes(dfw[,c("y",vars_num,"duration")],1) 
gm1<-glm( y ~ 
            duration +
            nr.employed +
            pdays +
            euribor3m +
            emp.var.rate +
            previous +
            cons.price.idx +
            campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw)
summary(gm1)
Anova(gm1)
```

Viendo el resultado de summary, podemos ver variables que tienen el p-value mayor a 0.1 (cons.cinf.idx, euribor3m), por lo que procedemos a quitarlas de nuestro modelo. 
Podemos ver que el deviance es inferior al null deviance.

```{r}
# chunk 170
gm2<-glm( y ~ 
            duration +
            nr.employed +
            pdays +
            emp.var.rate +
            previous +
            campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw)
vif(gm2)
```

Haciendo vif podemos ver que emp.var.rate tiene un valor mayor a 3, por lo que decidmos sacarla de nuestro modelo.

```{r}
# chunk 180
gm3<-glm( y ~ 
            duration +
            nr.employed +
            pdays +
            previous +
            campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw)
vif(gm3)
```


### Modelo de regresión polinómica

Hacemos un tanteo aplicando una tranformación polinomica de segundo grado a cada una de las variables.

```{r}
gm4<-glm(y~
           poly(duration,2) +
            poly(nr.employed,2) +
            poly(pdays,2) +
            poly(previous,2) +
            poly(campaign,2) +
            poly(age,2) +
            poly(cons.conf.idx,2), family = binomial, data = dfw
           )
summary(gm4)
```

En vista del summary, podemos omitir el termino cuadratico de las variables nr.employed, pdays, age, con.conf.idx.

```{r}
gm5<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
summary(gm5)
Anova(gm5)
vif(gm5)
marginalModelPlots(gm5)
```
Podemos ver que los p-values son inferiores a 0.1 para todas las variables, también vemos que el resultado del vif no presenta colinealidad.

Generalmente podemos ver que el modelo no se acerca tanto a los valores reales.

## Modelización con variables explicativas numéricas y categóricas
```{r}
# duration y f.duration
gm6<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
gm7<-glm(y~
           f.duration +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
BIC(gm7,gm6)

# pdays y f.pdays
gm8<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
gm9<-glm(y~
           poly(duration,2) +
            nr.employed +
            f.pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
BIC(gm9,gm8)

# previous y f.previous
gm10<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
gm11<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            f.previous +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
BIC(gm11,gm10)

# campaign vs f.campaign
gm12<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
gm13<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            f.campaign +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
BIC(gm13,gm12)

# age vs f.age
gm14<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
gm15<-glm(y~
           poly(duration,2) +
            nr.employed +
            pdays +
            poly(previous,2) +
            poly(campaign,2) +
            f.age +
            cons.conf.idx, family = binomial, data = dfw
           )
BIC(gm15,gm14)
```

A partir de los resultados de los BICs, nos quedamos con las versiones de las varibles númericas o de factores cuyo valor de BIC es menor.

Con el resutlado obtenido anteriormente, creamos un nuevo modelo.

```{r}
gm16<-glm(y~
           poly(duration,2) +
            nr.employed +
            f.pdays +
            poly(previous,2) +
            poly(campaign,2) +
            age +
            cons.conf.idx, family = binomial, data = dfw
           )
summary(gm16)
Anova(gm16)
vif(gm16)
```
Comprobamos el resultado y son correctos.

Ahora añadimos el resto de factores, utilizmaos un catdes para ver cuales están más relacionadas con nuesto target.
```{r}
catdes(dfw[,c("y",vars_cat)],1) 
```

Viendo el resultado del catdes, obtenemos que las variables que están más relacionadsa son outcome, month, job, contact, default, marital, housing y education. Como month tiene muchos niveles decidimos usar el month factorizado.

```{r}
gm17<-glm(y~poly(duration,2) +nr.employed +f.pdays +poly(previous,2) +poly(campaign,2) +age +cons.conf.idx+poutcome+ f.influentMonth + job+ contact+ default+ marital+ housing+ education, family = binomial, data = dfw)
Anova(gm17)
```
Seguimos cribando dado el resultado del Anova
```{r}
gm18<-glm(y~poly(duration,2) +nr.employed +poly(campaign,2) +age +poutcome+ f.influentMonth + contact+ default+ housing, family = binomial, data = dfw)
Anova(gm18)
vif(gm18)
```
Ahora las variables nos dan aceptables, con p-values menores a 0.1 y sin colinealidad.

Ahora hacemos un step con el criterio bayesiano, para validar el modelo
```{r}
gm19<-step(gm18,k=log(nrow(dfw)))
summary(gm19)
```
Hay que ver que todos los coeficientes sean calculables y que no tengamos ningun NA en el summary, en nuestro caso no tenemos niguno.

## Interacciones
```{r}
gm20<-glm(y~ (poly(duration,2) +nr.employed +poly(campaign,2) +age +poutcome+ f.influentMonth + contact+ default+ housing)^2, family = binomial, data = dfw)
Anova(gm20)
```


## Validación
# hacer tablas de confusion para el targer binario, y las predicciones. Para el numerico no hay qu ehacer predicciones




