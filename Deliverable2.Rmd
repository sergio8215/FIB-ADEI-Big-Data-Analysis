---
title: "Deliverable 2"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
#setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")

rm(list=ls())
load("data-INI2.RData")
```


##Valores propios y ejes dominantes

### Eigenvalues and dominant axes analysis. How many axes we have to interpret according to Kaiser and Elbow's rule?

Hemos decidido probar como se ve el PCA sin y con la variable pdays, ya que consideramos con una variable con bastantes missings, aún así aporta información por lo tanto la vamos a considerar.

```{r}
vars_num_sin_pday = vars_num[-3];
par(mfrow=c(1,2))
res2.pca<-PCA(df[,c('duration',vars_num_sin_pday)],quanti.sup=1)
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1)
par(mfrow=c(1,1))
```


Vemos que con pdays existe una relación inversa con previous, respecto a los dos ejes factoriales, sin pdays se puede ver que la contribución de la variable age con el segundo eje factorial es mayor, ya que graficamente tiene mayor magnitud ademas que las variables socio economicas, se ven mejor representadas en el primer eje factorial.


Por la ley de Kaiser, deberiamos utilizar los 3 primeros ejes factoriales, los cuales son mayores a 1. 
Por la ley de ElBow, al realizar el grafico podemos ver que la grafica empieza a ser plana a partir de la 2da dimension, es decir que se cogen las 2 primeras dimensiones.
 Si tomamos en cuenta el criterio del 80% se deberian coger las 4 primeras dimensiones.
 
 Para realizar el futuro analisi, combiene utilizar dimensiones pares, por lo que decidimos de solo usar 2.

```{r}
summary(res.pca,ncp=4,nb.dec=2)
plot(res.pca$eig[,1],main="Eigenvalues",type="o", col="blue")
```


#  Individuals point of view: Are they any individuals "too contributive"? To better understand the axes meaning use the extreme individuals. Detection of multivariant outliers and influent data.

Primero graficamos en rp los 15 individuos más contributivos en ambos ejes, luego analizamos los 5 individuos más contributivos en la dimensión 1 y 2. Al ver si estos tienen alguna relación significante, podemos decir que para los 5 individuos de la dimension 1, vemos que principalmente son gente mayor de 45años, todos han comprado el producto, han sido contactados mediante el móvil, han sido contactados previamente, comprado un producto en una campaña anterior, la duración de la llamada ha sido mayor a los 300s.

Para la dimension 2 podemos ver practicamente las mismas caracteristas menos la duración que ha sido menor. Cabe a destacar que sin embargo hay dos individuos que son muy contributivos en ambos ejes, eso hace pensar que pueden ser posibles outliers pero de igual forma los dejamos en los datos. 


```{r}

plot.PCA(res.pca, choix=c("ind"),cex=0.8,col.ind="grey70",select="contrib15",axes=c(1,2)) 
mas_ctr_dim1 <- sort(res.pca$ind$contrib[,1], decreasing = TRUE)[1:5]
mas_ctr_dim2 <- sort(res.pca$ind$contrib[,2], decreasing = TRUE)[1:5] # ver si hay alguna caracteristica relevnte, ver los 5 mas relevantes de este eje y del eje 2, ver que comparten en común.

# mas_ctr_dim1
#    40396     39592     38902     38814     36461 
#0.2482556 0.2196878 0.2057888 0.2053101 0.1994545  
# mas_ctr_dim2
#    40396     40703     39592     38902     39612 
#1.3837961 1.1876086 0.8973750 0.8642930 0.8630042 

df[names(mas_ctr_dim1),]
df[names(mas_ctr_dim2),]

# pendiente apuntar los indv mas ctr en colores diferente

```


### Interpreting the axes:  Variables point of view coordinates, quality of representation, contribution of the variables  

Al hacer el PCA con la variable target duration como suplementaria, podemos ver que su modulo es practicamente nulo, esto quiere decir que la variable no se ve representada en niguno de los ejes factoriles.

El eje horizontal está muy relacionado con las variables socio economicas, mirando el cos2 del summary podemos ver que las variables que estan mejor representadas con la dimension 1 son:
  euribor3m, emp.var.rate, nr.emplyed
Para el eje vertical: 
  pdays y previous

Para el eje vertical, podemos decir que esta relacionado con las campañas previas.

```{r}
par(mfrow=c(1,2))
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1)
summary(res.pca,ncp=4,nb.dec=2)
res.pca<-PCA(df[,c('y',vars_num)],quali.sup=1)
summary(res.pca,ncp=4,nb.dec=2)
par(mfrow=c(1,1))

```


### Perform a PCA taking into account also supplementary variables the supplementary variables can be quantitative and/or categorical

```{r}

# vars_factorizadas<- c("f.job","f.season","f.education","f.age","f.duration","f.campaign","f.pdays","f.previous");
vars_factorizadas<- c("f.job","f.season","f.education","f.age","f.pdays","y");

res.pca<-PCA(df[,c('duration',vars_num,vars_factorizadas)],quanti.sup=1, quali.sup = c(11:16))  # no ponerlas todas a la vez, poner por grupos. Pntar grupos de variables, si categorias quedan en el medio no valen de nada, hay que ver si categorias de las variables que estan lejos del centrode gravedad, son las que valen la pena. Fijarse que no cambian los valores de los ejes porque si no no tendremos referencia para comparar

plot(res.pca,choix="var")
plot(res.pca,choix="var", cex=0.75)

summary(res.pca)

plot.PCA(res.pca,choix="ind",invisible="ind")
lines(res.pca$quali.sup$coord[1:2,1:2],col="blue",lwd=2)
lines(res.pca$quali.sup$coord[3:6,1:2],col="cyan",lwd=2)


```



####################  ENUNCIADO  ###########################
K-Means Classification

    Description of clusters

Hierarchical Clustering

    Description of clusters

CA analysis for your data should contain your factor version of the numeric target (previous) in K= 7 (maximum 10) levels and 2 factors:

    Eigenvalues and dominant axes analysis. How many axes we have to consider
    Are there any row categories that can be combined/avoided to explain Duration target.

 MCA analysis for your data should contain:

    Eigenvalues and dominant axes analysis. How many axes we have to consider for next Hierarchical Classification stage?
    Individuals point of view: Are they any individuals "too contributive"? Are there any groups?
    Interpreting map of categories: average profile versus extreme profiles (rare categories)
    Interpreting the axes association to factor map.
    Perform a MCA taking into account also supplementary variables (use all numeric variables) quantitative and/or categorical. How supplementary variables enhance the axis interpretation?

 Hierarchical Clustering (from MCA)

    Description of clusters
    Parangons and class-specific individuals.
    Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on Duration target.
    Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on the binary target.
####################  FIN ENUNCIADO  #######################