---
title: "Deliverable 2"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
#setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")

rm(list=ls())
load("data-INI2.RData")
```


####################  ENUNCIADO  ###########################
PCA analysis for your data should contain:

    * Eigenvalues and dominant axes analysis. How many axes we have to interpret according to Kaiser and Elbow's rule?
    * Individuals point of view: Are they any individuals #preguntar "too contributive"? To better understand the axes meaning use the #preguntar extreme individuals. Detection of multivariant outliers and influent data.
    * Interpreting the axes:  Variables point of view coordinates, quality of representation, contribution of the variables  
    * Perform a PCA taking into account also supplementary variables the supplementary variables can be quantitative and/or categorical  

####################  FIN ENUNCIADO  #######################
#Análisis PCA
El análisis de componentes principales solo tiene sentido sobre variables numéricas. Primero vamos a obtener un data frame con solo las variables numéricas, centradas y reducidas, que llamaremos Xs. Comprobamos los tres primeros elementos comparándolos con los valores centrados y reducidos esperados (age'= (age-mean)/sd).

```{r}
Xs<-scale(df[,vars_num])
mean(df$age);sd(df$age)
Xs[1:3,1];((df$age-mean(df$age))/sd(df$age))[1:3]
```

Para obtener Z podemos usar la función cor() que, viendo la primera fila, vemos que se obtiene el mismo resultado que ejecutando el calculo manual de la multiplicación matricial de Xs. Z se obtiene con el producto matricial de la traspuesta de Xs por Xs. Multiplicadas en este orden obtenemos la correlación entre variables. En el orden inverso se obtiene la correlación entre individuos.

```{r}
Z<-t(Xs)%*%Xs/(nrow(df)-1);
Z[1,]
cor(df[,vars_num])[1,]
```


##Valores propios y ejes dominantes
# preguntar eigens vectors y aigen values. tambien porque se hace la matriz de correlacion con la misma matriz del vector propio - sea a una matriz cuadrada, nxn entonces un vector propio es aquel U tal qeue al multriplcarlo por la matriz cuadrada optengo el mismo vector propio por un escalar. El vector propio se relaciona mejor que los ejes por que las direcciones donde esta la varianza es casualmente donde esta el vector propio. La relacion de los datos proyectados y los vectores propios es lo de la transparencia 70 de (componentes principales)
# preguntar, pdays hay que cambiarlo al maximo mas uno ahora o antes en el deliberable 1

- para keiser si tiene el valo propio mayor a uno, esto debe estar normalizado. Si es menor a uno seria ruido
- la regla del codo se grafica la varianza de cada dimension, normalmente un barplot o screeplot el punto al partir el cual comienza a estar practicamente plano el screetplot.
- Criterio de la cantidad de la varianza explicada, en datos abundantes suele ser el 80%, pero en otros puede estar en 90 95%, depende.

    
### Eigenvalues and dominant axes analysis. How many axes we have to interpret according to Kaiser and Elbow's rule?


 Por la ley de Kaiser, cojemos los 3 primeros ejes factoriales, los cuales son mayores a 1. 
 Por la ley de ElBow, al realizar el grafico podemos ver que la grafica empieza a ser plana a partir de la 3ra dimension, es decir que se cogen las 3 primeras dimensiones.

```{r}
eigens<-eigen(Z)
t(eigens$vectors)%*%eigens$vectors
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1) # Hay que poner como suplemenmtaria la variable target. Convé treure pdays ja que té molts missings
#La flecha pequeña de duration significa que poco se podrá relacionar el resto de variables con el target duration. Conviene poner pdays en max+1 en lugar de 999

res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1,axes=3:4)#para ver ejes 3 y 4  # preguntar porque ver ejes 3 y 4 

summary(res.pca,ncp=4,nb.dec=2)
#Eigenvalues
#                      Dim.1  Dim.2  Dim.3  Dim.4  Dim.5  Dim.6  Dim.7  Dim.8  Dim.9
#Variance               3.88   1.36   1.11   0.97   0.83   0.43   0.38   0.02   0.01
#% of var.             43.15  15.17  12.32  10.74   9.25   4.75   4.25   0.27   0.12
#Cumulative % of var.  43.15  58.31  70.63  81.37  90.62  95.37  99.62  99.88 100.00


plot(res.pca$eig[,1],main="Eigenvalues",names.arg=paste("dim",1:nrow(res.pca$eig)),type="o", col="blue")

```

### Interpreting the axes:  Variables point of view coordinates, quality of representation, contribution of the variables  

Al hacer el PCA con la variable target duration, podemos ver que su modulo es practicamente nulo, esto quiere decir que la variable no se ve representada en niguno de los ejes factoriles.

El eje horizonatal está muy relacionado con nr.emplyed, tambien con campaign pero en menor magnitud. Para el eje vertical, vemos que hay una relación con age.



```{r}
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1)

res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1,axes=3:4) # para ver ejes 3 y 4  # preguntar porque ver ejes 3 y 4 
```


### Perform a PCA taking into account also supplementary variables the supplementary variables can be quantitative and/or categorical

```{r}

res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=c(1,12,13,14), quali.sup = c(2,3,4,6,7))

```



####################  ENUNCIADO  ###########################
K-Means Classification

    Description of clusters

Hierarchical Clustering

    Description of clusters

CA analysis for your data should contain your factor version of the numeric target (previous) in K= 7 (maximum 10) levels and 2 factors:

    Eigenvalues and dominant axes analysis. How many axes we have to consider
    Are there any row categories that can be combined/avoided to explain Duration target.

 MCA analysis for your data should contain:

    Eigenvalues and dominant axes analysis. How many axes we have to consider for next Hierarchical Classification stage?
    Individuals point of view: Are they any individuals "too contributive"? Are there any groups?
    Interpreting map of categories: average profile versus extreme profiles (rare categories)
    Interpreting the axes association to factor map.
    Perform a MCA taking into account also supplementary variables (use all numeric variables) quantitative and/or categorical. How supplementary variables enhance the axis interpretation?

 Hierarchical Clustering (from MCA)

    Description of clusters
    Parangons and class-specific individuals.
    Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on Duration target.
    Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on the binary target.
####################  FIN ENUNCIADO  #######################