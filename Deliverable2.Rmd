---
title: "Deliverable 2"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")
#setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")

#rm(list=ls())
load("data-INI2.RData")
```


##Valores propios y ejes dominantes

### Eigenvalues and dominant axes analysis. How many axes we have to interpret according to Kaiser and Elbow's rule?

Hemos decidido probar como se ve el PCA sin y con la variable pdays, ya que consideramos que es una variable con bastantes missings, aún así aporta información por lo tanto la vamos a considerar.

```{r}
vars_num_sin_pday = vars_num[-3];
res2.pca<-PCA(df[,c('duration',vars_num_sin_pday)],quanti.sup=1)
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1)
```

Vemos que con pdays existe una relación inversa con previous, respecto a los dos ejes factoriales, sin pdays se puede ver que la contribución de la variable age con el segundo eje factorial es mayor, ya que gráficamente tiene mayor magnitud además que las variables socio económicas, se ven mejor representadas en el primer eje factorial.

Por la ley de Kaiser, deberíamos utilizar los 3 primeros ejes factoriales, los cuales son mayores a 1. 
Por la ley de ElBow, al realizar el gráfico podemos ver que la gráfica empieza a ser plana a partir de la 2da dimensión, es decir que se cogen las 2 primeras dimensiones.

Si tomamos en cuenta el criterio del 80% se deberían coger las 4 primeras dimensiones.
 
Para realizar el futuro análisis, conviene utilizar dimensiones pares, por lo que decidimos solo usar 2.

```{r}
summary(res.pca,ncp=4,nb.dec=2)
plot(res.pca$eig[,1],main="Eigenvalues",type="o", col="blue")
```


##  Individuals point of view: Are they any individuals "too contributive"? To better understand the axes meaning use the extreme individuals. Detection of multivariant outliers and influent data.

Primero graficamos en rp los 15 individuos más contributivos en ambos ejes, luego analizamos los 5 individuos más contributivos en la dimensión 1 y 2. Al ver si estos tienen alguna relación significativa, podemos decir que para los 5 individuos de la dimension 1, vemos que principalmente son gente mayor de 45años, todos han comprado el producto, han sido contactados mediante el móvil, han sido contactados previamente, comprado un producto en una campaña anterior y la duración de la llamada ha sido mayor a los 300s.

Para la dimensión 2 podemos ver prácticamente las mismas características menos la duración que ha sido menor. Cabe destacar sin embargo que hay dos individuos que son muy contributivos en ambos ejes, eso hace pensar que pueden ser posibles outliers pero de igual forma los dejamos en los datos. 


```{r}
plot.PCA(res.pca, choix=c("ind"),cex=0.8,col.ind="grey70",select="contrib15",axes=c(1,2)) 
mas_ctr_dim1 <- sort(res.pca$ind$contrib[,1], decreasing = TRUE)[1:5]
mas_ctr_dim2 <- sort(res.pca$ind$contrib[,2], decreasing = TRUE)[1:5]
df[names(mas_ctr_dim1),]
df[names(mas_ctr_dim2),]
```

## Interpreting the axes:  Variables point of view coordinates, quality of representation, contribution of the variables  

Al hacer el PCA con la variable target duration como suplementaria, podemos ver que su módulo es prácticamente nulo, esto quiere decir que la variable no se ve representada en niguno de los ejes factoriales.

El eje horizontal está muy relacionado con las variables socio económicas, mirando el cos2 del summary podemos ver que las variables que están mejor representadas con la dimensión 1 son:
  euribor3m, emp.var.rate, nr.emplyed
Para el eje vertical: 
  pdays y previous

Para el eje vertical, podemos decir que está relacionado con las campañas previas.

Al hacer el PCA con la variable target Y como suplementaria, podemos ver que en el gráfico de rp, el factor NO, esta muy cerca del centro, por lo que no se ve representada en estos ejes factoriales. En cambio el factor SI, está a una distancia mayor del centro, aunque poco significativa.

```{r}
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1)
summary(res.pca,ncp=4,nb.dec=2)
res.pca<-PCA(df[,c('y',vars_num)],quali.sup=1)
summary(res.pca,ncp=4,nb.dec=2)
```

## Perform a PCA taking into account also supplementary variables the supplementary variables can be quantitative and/or categorical

Hemos dividido el plot en diferentes partes, para así poder entender y ver mejor el resultado.
Para la primera dimensión podemos ver que para los niveles mejor representados son:
f.season.jun-aug, f.previous-(0.9,1], y.no, y.yes.

Para la segunda dimsensión, las que se ven mejor representadas son:
f.pdays-[0,22],f.pdays-(22,23], f.previous-(1,6]


```{r}
vars_factorizadas<- c("f.job","f.season","f.education","f.age","f.duration","f.campaign","f.pdays","f.previous","y");

res.pca<-PCA(df[,c('duration',vars_num, "f.job","f.season")],quanti.sup=1, quali.sup = c(11:12))
plot.PCA(res.pca,choix="ind",invisible="ind",cex=0.75)

res.pca<-PCA(df[,c('duration',vars_num,"f.education","f.age")],quanti.sup=1, quali.sup = c(11:12))
plot.PCA(res.pca,choix="ind",invisible="ind",cex=0.75)

res.pca<-PCA(df[,c('duration',vars_num,"f.pdays","y")],quanti.sup=1, quali.sup = c(11:12))
plot.PCA(res.pca,choix="ind",invisible="ind",cex=0.75)

res.pca<-PCA(df[,c('duration',vars_num,vars_factorizadas)],quanti.sup=1, quali.sup = c(11:19),graph=FALSE)

fviz_pca_var(res.pca, col.var = "contrib",gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel = TRUE)

summary(res.pca,dig = 2, nbelements= 30, nbind=3, ncp=2)
```

## K-Means Classification

Hemos graficado los grupos separados en 3, 4, 5 y 6 clusters, para los cuales nos parece que gráficamente con 4 clusters los grupos están bien definidos, por lo que decidimos usar 4 clusters los cuales analizaremos seguidamente.


```{r}
dclu<- res.pca$ind$coord[,1:2]; # los dos ejes

kcla<- kmeans(dclu,4);

df$cluster3 = factor(kmeans(dclu,3)$cluster);
df$cluster4 = factor(kmeans(dclu,4)$cluster);
df$cluster5 = factor(kmeans(dclu,5)$cluster);
df$cluster6 = factor(kmeans(dclu,6)$cluster);

res.pca<-PCA(df[,c('duration',vars_num, "cluster3")],quanti.sup=1, quali.sup = 11, graph=FALSE)
plot.PCA(res.pca,choix="ind",habillage=11,select=0 ,cex=0.75)
res.pca<-PCA(df[,c('duration',vars_num, "cluster4")],quanti.sup=1, quali.sup = 11, graph=FALSE)
plot.PCA(res.pca,choix="ind",habillage=11,select=0 ,cex=0.75)
res.pca<-PCA(df[,c('duration',vars_num, "cluster5")],quanti.sup=1, quali.sup = 11, graph=FALSE)
plot.PCA(res.pca,choix="ind",habillage=11,select=0 ,cex=0.75)
res.pca<-PCA(df[,c('duration',vars_num, "cluster6")],quanti.sup=1, quali.sup = 11, graph=FALSE)
plot.PCA(res.pca,choix="ind",habillage=11,select=0 ,cex=0.75)

df <- df[,c(1:29, 31)] # guardamos la clasificación en 4 clusters
```
 
## Description of clusters

Viendo el chi-square test, podemos saber qué variables se utilizarán para caracterizar nuestros 4 clusters. 
Viendo las categorías donde el P-value es casi 0 podemos ver que las categorías que cumplen estas caracteristicas son:
month (y por extensión también f.season), poutcome, f.pdays, f.previous, contact, y, job(f.job), default, f.age, f.campaign, marital. Ahora veremos que categorías de estas variables son las que caracterizan estos clusters.

Para el catdes del cluster 1, hemos podido ver las categorías que mejor lo definen, la temporada de verano es la que mejor lo caracteriza, f.season.Jun-Aug, tenemos también un poutcome que nos indica que ninguno de los individuos ha sido contactado previamente, podemos ver que y.no representa el 95% de este cluster, han sido contactados en su mayoría por teléfono fijo, también podemos ver que este cluster está ligeramente relacionado con la categoría f.job.Serv-Tech-BlueC. En conclusión podemos decir que este cluster está caracterizado por:
	- Meses de jun-Ago
	- No han sido contactados previamente
	- Han sido contactados más de una vez en la campaña actual
	- Contactados por teléfono fijo
	- Trabajo normalmente es, servicio, técnicos o blue collar.
	- No compraron el producto en su mayoría.
	
Para el cluster 2, tenemos:
	- La temporada de mar-may están sobrerepresentadas en este cluster
	- Han sido contacados en su mayoría por teléfono móvil
	- No han comprado el producto en campañas anteriores
	- Han sido contacados en camapañas previas
	- La categoría student está sobrerepresentada
	- La aceptación del producto está sobrerepresentada también
	
Para el cluster 3, tenemos:
	- Temporada de Sep-Dec
	- Contactados por móvil en su mayoría
	- La categoría de job.management está sobrerepresentada
	- No han adquirido el producto
	- Una gran cantidad de individuos rechazó el producto (y.no)
	
Para el cluster 4, podemos ver que aglutina individuos muy bien caracterizados por las siguientes variables:
	- Han sido contactados previamente f.pdays[0,22]
	- Han comprado el producto en una campaña previa
	- Han comprado el producto y.yes
	- Temporada de Sep-Dec
	- Han sido contactados por móvil
	- Una parte importante son job.retired
	- Una edad de f.age-(50,92]

```{r}
catdes(df, 30, proba = 0.001)
```

## Hierarchical Clustering
  
Al hacer el HCPC podemos ver que el gráfico de ganancia de inercia nos da la mayoría en dos variables, y luego dos picos más pequeños.  
  
Ahora vemos el clustering no supervisado. Vamos a clasificar estos clusters.  
  
Para el cluster 1:  
- Está caracterizado por personas que han sido contactados previamente  
- Han aceptado el producto  
- Se han contactado en f.season.Sep-Dec  
- Tienen una sobrerepresentación de f.job.Entrep-Retired-selfEmpl  
- Llamadas de duración mayor a 3min  

Para el cluster 2:  
- Han sido contactados f.season.Mar-May  
- Han sido contactados en campañas previas  
- Han aceptado el producto (y.yes)  
  
Para el cluster 3:  
- Han sido contactados previamente  
- No han sido contactados en campañas previas  
- Han sido contactados en la temporada de f.season.Jun-Aug  
- Han rechazado el producto  
- Tienen una leve representación de f.job.Serv-Tech-BlueC  
  

```{r}
res.pca<-PCA(df[,c('duration',vars_num,vars_factorizadas)],quanti.sup=1, quali.sup = c(11:19), ncp=2, graph=FALSE)
```
# añadir a mano
```{r setup, include=FALSE}
res.hcpc<-HCPC(res.pca,order=TRUE)
attributes(res.hcpc)

summary(res.hcpc$data.clust)
attributes(res.hcpc$desc.var)
# Factors globally related to clustering partition
res.hcpc$desc.var$test.chi2
# Categories over/under represented in each cluster
res.hcpc$desc.var$category
# Numeric variables globally related to clustering partition
res.hcpc$desc.var$quanti.var
res.hcpc$desc.var$quanti

### desc.ind ###
### C. The description of the clusters by the individuals ###
names(res.hcpc$desc.ind)
res.hcpc$desc.ind$para  # Close to center of gravity
res.hcpc$desc.ind$dist  
```
# fin añadir a mano

## CA analysis for your data should contain your factor version of the numeric target (duration) in K= 7 (maximum 10) levels and 2 factors:
### Eigenvalues and dominant axes analysis. How many axes we have to consider are there any row categories that can be combined/avoided to explain Duration target.

Para experimentar y para que tenga más sentido el análisis de correspondencias, refactorizaremos a 8 niveles la variable duration.

Ahora hacemos el análisis de correspondencias entre nuestra nueva duration factorizada y f.age. Para saber cuantas dimensiones debemos considerar, obtenemos la media de los eigenvalues. Vemos que solamente tiene sentido considerar el primer eje, ya que este es el único valor mayor a la media (kaiser).

Al graficar el CA, podemos ver que los 2 niveles con menores edades, son los que menos representados en ese eje.
Para duration, los niveles mejor representados en el eje son los de mayor y menor duración.

Al ejecutar la función del chisq.test podemos ver que el pvalue es muy grande, lo que nos puede decir que la probabilidad de que no tengan relación es muy grande.

### CA - duration vs f.age

```{r}
# Para duration
aux2<-c(5,60,120,150,180,240,300,1200,2100) # Niveles "naturales"
duration_k8<-factor(cut(df$duration,breaks=aux2,include.lowest=T))
table(duration_k8)
levels(duration_k8)<-paste0("f.duration-",levels(duration_k8)) # Hacemos las etiquetas más informativas
summary(duration_k8)

res.ca<-CA(table(df$f.age,duration_k8))
attributes(res.ca)
res.ca$eig
mean(res.ca$eig[,1])  # Mean of eigenvalues
sum(res.ca$eig[,1])  # Total inertia

# Rows
res.ca$row
# Columns: the same
res.ca$col

# Link levels in rows
plot.CA(res.ca)
lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="darkblue")
lines(res.ca$col$coord[,1],res.ca$col$coord[,2],lwd=2,col="red")

# Phi2 = Intensity of the association Chisq/nbobservations
sum(res.ca$eig[,1]) # Total Inertia = Phi2
# H0: f.duration - f.age independency
chisq.test(table(df$f.age,duration_k8))

```

### CA - Education vs f.duration
  
Para la segunda prueba decidimos utilizar duration junto con education. Para education usaremos la variable original con todos sus niveles menos el nivel illiterate el cual nos puede causar inconvenientes.  
  
Por kaiser vemos que las primeras dos dimensiones están por encima de la media, por lo que son las que cogemos.  
  
Podemos ver que para la primera dimensión los valores más lejanos del centro son los niveles de education.basic_6y, education.university.degree, para la primera dimensión. Para la segunda tenemos, f.duration(150,180], education.professioal.course, esto nos puede decir qué niveles se ven mejor representados en las dimensiones.  

```{r}
#Education
table(df$education)
education_k6<-df$education
education_k6[which(education_k6=="education.illiterate")]<-"education.basic.4y"
education_k6=factor(education_k6)

par(cex=0.8)
res.ca<-CA(table(education_k6,duration_k8))
res.ca$eig
mean(res.ca$eig[,1])

# Rows
res.ca$row
# Columns: the same
res.ca$col

# Link levels in rows
plot.CA(res.ca)
lines(res.ca$row$coord[,1],res.ca$row$coord[,2],lwd=2,col="darkblue")
lines(res.ca$col$coord[,1],res.ca$col$coord[,2],lwd=2,col="red")

# Phi2 = Intensity of the association Chisq/nbobservations
sum(res.ca$eig[,1]) # Total Inertia = Phi2

chisq.test(table(education_k6,duration_k8))
# Traditional analysis
table(df$y,duration_k8)
chisq.test(table(df$y,duration_k8))
```