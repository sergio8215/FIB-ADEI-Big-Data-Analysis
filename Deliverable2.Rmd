---
title: "Deliverable 2"
author: "Guillem Valls, Sergio Mazzariol"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '3'
  html_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Load Required Packages: to be increased over the course

requiredPackages <- c("mvoutlier","chemometrics","mice","missForest","missMDA","DMwR","pbkrtest","jomo","readxl","haven","sf","rgdal","missMDA","effects","FactoMineR","car","factoextra","RColorBrewer","ggplot2","dplyr","data.table", "ggmap","ggthemes","knitr","MVA")
missingPackages <- requiredPackages[!(requiredPackages %in% as.vector(installed.packages(lib.loc="~/R/win-library/3.5")[,"Package"]))]

if(length(missingPackages)) install.packages(missingPackages)
lapply(requiredPackages, require, character.only = TRUE)

```


```{r include=FALSE}
#setwd("C:/Users/Sergio/Dropbox/UPC/FIB/Analisis de datos y explotacion de la informacion (ADEI)/FIB-ADEI-Big-Data-Analysis")

setwd("C:/Users/usuario/Documents/ADEI/FIB-ADEI-Big-Data-Analysis")

rm(list=ls())
load("data-INI2.RData")
```


####################  ENUNCIADO  ###########################
PCA analysis for your data should contain:

    Eigenvalues and dominant axes analysis. How many axes we have to interpret according to Kaiser and Elbow's rule?
    Individuals point of view: Are they any individuals "too contributive"? To better understand the axes meaning use the extreme individuals. Detection of multivariant outliers and influent data.
    Interpreting the axes:  Variables point of view coordinates, quality of representation, contribution of the variables  
    Perform a PCA taking into account also supplementary variables the supplementary variables can be quantitative and/or categorical  

####################  FIN ENUNCIADO  #######################
#Análisis PCA
El análisis de componentes principales solo tiene sentido sobre variables numéricas. Primero vamos a obtener un data frame con solo las variables numéricas, centradas y reducidas, que llamaremos Xs. Comprobamos los tres primeros elementos comparándolos con los valores centrados y reducidos esperados (age'= (age-mean)/sd).

```{r}
Xs<-scale(df[,vars_num])
mean(df$age);sd(df$age)
Xs[1:3,1];((df$age-mean(df$age))/sd(df$age))[1:3]
```

Para obtener Z podemos usar la función cor() que, viendo la primera fila, vemos que se obtiene el mismo resultado. Z se obtiene con el producto matricial de la traspuesta de Xs por Xs. Multiplicadas en este orden obtenemos la correlación entre variables. En el orden inverso se obtiene la correlación entre individuos.

```{r}
Z<-t(Xs)%*%Xs/(nrow(df)-1);
Z[1,]
cor(df[,vars_num])[1,]
```


##Valores propios y ejes dominantes

```{r}
eigens<-eigen(Z)
t(eigens$vectors)%*%eigens$vectors
res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1)#Hay que poner como suplemenmtaria la variable target. Convé treure pdays ja que té molts missings
#La flecha pequeña de duration significa que poco se podrá relacionar el resto de variables con el target duration. Conviene poner pdays en max+1 en lugar de 999

res.pca<-PCA(df[,c('duration',vars_num)],quanti.sup=1,axes=3:4)#para ver ejes 3 y 4

summary(res.pca,ncp=4,nb.dec=2)
#Eigenvalues
#                      Dim.1  Dim.2  Dim.3  Dim.4  Dim.5  Dim.6  Dim.7  Dim.8  Dim.9
#Variance               3.88   1.36   1.11   0.97   0.83   0.43   0.38   0.02   0.01
#% of var.             43.15  15.17  12.32  10.74   9.25   4.75   4.25   0.27   0.12
#Cumulative % of var.  43.15  58.31  70.63  81.37  90.62  95.37  99.62  99.88 100.00

#Por el criterio de kaiser cogeríamos las primeras 3 variables, ya que son mayores que 1. Vemos que la dimensiíon 1 vale por 3.88 variables de información
#miramos de cumplir los tres criterios, el de kaiser, el del 80% y otro que no me acuerdo.
```


####################  ENUNCIADO  ###########################
K-Means Classification

    Description of clusters

Hierarchical Clustering

    Description of clusters

CA analysis for your data should contain your factor version of the numeric target (previous) in K= 7 (maximum 10) levels and 2 factors:

    Eigenvalues and dominant axes analysis. How many axes we have to consider
    Are there any row categories that can be combined/avoided to explain Duration target.

 MCA analysis for your data should contain:

    Eigenvalues and dominant axes analysis. How many axes we have to consider for next Hierarchical Classification stage?
    Individuals point of view: Are they any individuals "too contributive"? Are there any groups?
    Interpreting map of categories: average profile versus extreme profiles (rare categories)
    Interpreting the axes association to factor map.
    Perform a MCA taking into account also supplementary variables (use all numeric variables) quantitative and/or categorical. How supplementary variables enhance the axis interpretation?

 Hierarchical Clustering (from MCA)

    Description of clusters
    Parangons and class-specific individuals.
    Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on Duration target.
    Comparison of clusters obtained after K-Means (based on PCA) and/or Hierarchical Clustering (based on PCA) focusing on the binary target.
####################  FIN ENUNCIADO  #######################